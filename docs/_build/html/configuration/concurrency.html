
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

    <title>Concurrency &#8212; pytranscoder 2.2.5 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Cluster Configuration" href="cluster.html" />
    <link rel="prev" title="Configuration" href="configuration.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="concurrency">
<h1>Concurrency<a class="headerlink" href="#concurrency" title="Permalink to this heading">¶</a></h1>
<p>Concurrency, or multitasking, is simply the act of doing multiple tasks at once. Computers do this very well.
However, some activities do not lend themselves well to concurrency - encoding and decoding video is one of them.
On a typical machine this is a very CPU-intensive activity, especially encoding, and leaves little room or other processes to run well.
So CPU and video card vendors have stepped up to provide dedicated hardware for this purpose. Modern Intel CPUs have hardware collectively
referred to as QSV - QuickSync Video - for doing this. AMD’s version is AMF/VCE. Also, modern media players like VLC will use these
extensions to make HD video playback smooth and less CPU-intensive.</p>
<p>For people who encode a lot, using QSV or AMF can speed up your job up to 4x. But if you want a faster solution both nVidia and AMD produce
graphics cards (GPU) cable of encoding at over 10x - that’s basically 6 minutes to encode a 1 hour HD video. Furthermore, you can run multiple
encodes at the same time since most processing is handled by the GPU and not the CPU. For example, an nVidia 970 can handle 2 concurrent
jobs hardware decoding and encoding of H264 or HEVC(H265) video. So this means we can encode 2 of our theoretical 1 hour videos in 6 minutes.</p>
<p>pytranscoder was originally created to manage a pair of jobs running on a local host in this manner, handing out jobs to the next available
slot as other jobs finished.  It has since grown into a configurable workflow manager with multi-host clustering support.</p>
<p>You can successfully achieve concurrency with either (or both) of these approaches:</p>
<section id="non-clustered">
<h2>Non-Clustered<a class="headerlink" href="#non-clustered" title="Permalink to this heading">¶</a></h2>
<p>A cluster is just a group of machines working together. If you have access to multiple machines skip down to the next section.
But if you just want to encode on your single host machine your setup overhead is very small.  You’ve probably already been through
the configuration section and may have noticed the <strong>queues</strong> section under Global config.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">queues</span><span class="p">:</span>
<span class="w">    </span><span class="nt">qsv</span><span class="p">:</span><span class="w">   </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">    </span><span class="nt">cuda</span><span class="p">:</span><span class="w">  </span><span class="l l-Scalar l-Scalar-Plain">2</span>
</pre></div>
</div>
<p>This is optional and only needed to enable concurrency on your single (local) host.  This configuration snippet reads “create a queue
called <em>csv</em> that does 1 encode at a time and another called <em>cuda</em> which can do 2 at a time.” They are simply a way of controlling the
number of concurrent jobs.
So, by themselves these settings do nothing. To make useful you need to associate various <strong>profiles</strong> with a queue.  A good example is
to assign all of your profiles that perform nVidia-based encoding to the <em>cuda</em> queue. When you run an encode and specifiy one of these
profiles, or when a rule selects one, the jobs will be managed 2 at a time.</p>
<p>A profile is assigned to a queue using the <strong>queue:</strong> directive, as seen in the sample profiles in the configuration section.
If a profile has no queue:, it defaults to single, sequential encoding - i.e. one job at a time.</p>
<p>So you’ve probably noticed the qsv: 1 queue above and are wondering why define a queue of 1 if the default is 1 anyhow. Well there’s a
good reason. Even though the qsv queue is set to 1, by defining it as another queue it can actually run concurrently with the other queue.
Wait, what??</p>
<p>Consider this scenario.  You have an 8th generation Intel i5 and an nVidia 970 GPU with 4gb. You have a bunch of videos to transcode and
you want to max out your system to get it done.  You can define one profile (my_qsv) assigned to the <strong>qsv</strong> queue and another (my_cuda) to the <strong>cuda</strong> queue.
Depending on whether you are using the rules engine or commandline you can spread your videos across both profiles, this assigning them
across 2 queues.  You’ll end up with 2 encodes running on your nVidia GPU and 1 on your CPU/QSV hardware. That’s 3 concurrent encodes:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>pytranscoder<span class="w"> </span>-p<span class="w"> </span>my_qsv<span class="w"> </span>/downloads/show.s01e0*<span class="w"> </span>-p<span class="w"> </span>my_cuda<span class="w"> </span>/downloads/show.s01e1*
</pre></div>
</div>
<p>Only 2 concurrent jobs are known to work with nVidia 970 and nVidia 1050ti cards, but more may work on bigger more expensive cards.</p>
</section>
<section id="clustered">
<h2>Clustered<a class="headerlink" href="#clustered" title="Permalink to this heading">¶</a></h2>
<p>Clustering allows you to use available machines accessible on your network for encoding duties. You don’t need to install anything on them
other than <strong>ffmpeg</strong> and <strong>ssh</strong>, which is probably already there.  See Cluster Configuration.</p>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">pytranscoder</a></h1>








<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="quickstart.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="configuration.html">Configuration</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Concurrency</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#non-clustered">Non-Clustered</a></li>
<li class="toctree-l2"><a class="reference internal" href="#clustered">Clustered</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="cluster.html">Cluster Configuration</a></li>
<li class="toctree-l1"><a class="reference internal" href="cluster.html#ssh">SSH</a></li>
<li class="toctree-l1"><a class="reference internal" href="cluster.html#pytranscoder-agent">Pytranscoder Agent</a></li>
<li class="toctree-l1"><a class="reference internal" href="../usage/running-local.html">Running (Local)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../usage/running-clustered.html">Running (Clustered)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../usage/includes.html">Using includes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../usage/mixins.html">Using Mixins</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
      <li>Previous: <a href="configuration.html" title="previous chapter">Configuration</a></li>
      <li>Next: <a href="cluster.html" title="next chapter">Cluster Configuration</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2019-2023, Marshall L Smith Jr.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 6.1.3</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
      |
      <a href="../_sources/configuration/concurrency.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>